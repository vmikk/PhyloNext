#!/usr/bin/env Rscript

## Aggregate Biodiverse randomization results (from different threads)
## and estimate Z-scores


## Usage example:
# ./13_Aggregate_Biodiverse_results.R \
#   --observed "obs.csv" \
#   --randomized "rnd.txt" \
#   --output "Biodiverse_input" \
#   --threads 1 \

# Input with randomized results (`rnd.txt`) should contain paths to the files!
# each starting from a new line


## TO DO:
# - deal with NAs in Z-scores
# - add ranks to the results


## https://biodiverse-analysis-software.blogspot.com/2016/08/easier-to-use-randomisation-results.html
## https://github.com/shawnlaffan/biodiverse/wiki/AnalysisTypes#randomisations

## Biodiverse outputs:
# 1. `SPATIAL_RESULTS` contains the observed results for each group (cell)
# 2. `rand--SPATIAL_RESULTS` contains indices to track the randomisations for each index in SPATIAL_RESULTS
#    For example, for PE_WE there will be C_PE_WE, Q_PE_WE, T_PE_WE and P_PE_WE collating, respectively, 
#    the number of times observed PE_WE was higher than that generated using the randomised data, 
#    the number of times observed PE_WE was compared against the scores from the randomised data, 
#    the number of times the observed and random scores were tied, 
#    and the proportion of iterations that the observed score was higher than the random scores (P_PE_WE = C_WE_PE / Q_PE_WE).
# 3. `rand--p_rank--SPATIAL_RESULTS` contains a set of results using the same names as the original indices in SPATIAL_RESULTS,
#    but converted to their rank relative positions.  
#    Importantly, the lower tail ranks take into account any ties in the comparisons, thus simplifying any code that uses theses results.
#    Also, any value that would be considered not significant at alpha=0.05 (one tailed, high or low) is converted to undef (null).
#    This makes any plots of the results clearer within Biodiverse so one can more easily see which groups would pass a one-tailed high or low test.

## What do the names and values in the spatial comparison lists mean?
## The indices shown are those used in the comparisons, prefixed by a letter with an underscore.
#   C_* (e.g. C_ENDC_CWE, C_NUM_MAX) is the number of times the original value was higher than the comparison.
#   Q_* (e.g. Q_ENDC_CWE, Q_NUM_MAX) is the number of comparisons (q = quantum). We could use the number of iterations directly, however there may be cases where undefined values result for some indices. We cannot compare undefined with a number, and we also cannot be sure that the number of times undef results is the same for all indices.
#   P_* (e.g. P_ENDC_CWE, P_NUM_MAX) is the fractional ranking of the original value against those generated by the set of randomisations, calculated as C_* / Q_*. Multiply by 100 to get a percentile. The P_* score can be converted into a p-score in the normal way, i.e. if P_* = 0.99 then the original measure is higher than the randomised versions 99 times out of every hundred. If one considers higher scores to be more significant (a one tailed test) then this is the same as a p score of 0.01. One-tailed tests for low values need to account for any ties (see next point) to get the correct rank, but the interpretation is then the same. Obviously one changes the interpretation appropriately if it is a two tailed system, e.g. the mean of numeric labels (NUM_MEAN) can be higher or lower than the set of randomisation results. So long as it is in one of the tails of the distribution then the original result is significantly more extreme than that generated by the randomisation (e.g. (C_NUM_MEAN + T_NUM_MEAN) / Q_NUM_MEAN < 0.025 or P_NUM_MEAN > 0.975 for an alpha of 0.05).
#   T_* (e.g. T_ENDC_CWE, T_NUM_MAX) is the number of ties, being the count of the number of times the original value was the same as the randomised value. If there were no ties then this index is not listed.
#   SUMX_* and SUMXX_* (e.g. SUMX_ENDC_CWE, SUMXX_NUM_MAX) are the sums and sums of squared values for the random indices. These are used to calculate z-scores of the distributions as an alternative to the rank relative scoring system

## Z-score formula derivation:
# xm = mean(xi)
# var = 1/N * sum(xi - xm)^2 = 1/N * sum(xi^2 - 2*xm*xi + xm^2) = 
#     = 1/N * sum(xi^2) - 2*xm*[ 1/N * sum(xi) ] + xm^2 = 
#     = 1/N * sum(xi^2) - 2*(xm^2) + xm^2 = 
#     = 1/N * sum(xi^2) - xm^2
#
# SUMX = sum(xi); SUMXX = sum(xi^2)
# xm = SUMX / N
# sd = sqrt( SUMXX/N  - (SUMX/N)^2 )
# z  = (obs - xm) / sd  = (obs -  SUMX/N) / sd

## Z-score interpretation:
# the values outside the interval [-1.96,1.96] being significant for two tailed test with an alpha of 0.05, providing the number of samples is large. 



############################################## Parse input parameters

## Check time
start_time <- Sys.time()


cat("Parsing input options and arguments...\n")

suppressPackageStartupMessages(require(optparse))

## Parse arguments
option_list <- list(
  make_option(c("-r", "--observed"), action="store", default=NA, type='character', help="Input file (CSV) with Biodiverse results - observed indices"),
  make_option(c("-z", "--randomized"),  action="store", default=NA, type='character', help="Input file (TXT) with paths to Biodiverse randomized results `rand--SPATIAL_RESULTS.csv`"),

  make_option(c("-t", "--threads"), action="store", default=2L, type='integer', help="Number of CPU threads for arrow, default 4"),
  make_option(c("-o", "--output"), action="store", default=NA, type='character', help="Output file")
)
opt <- parse_args(OptionParser(option_list=option_list))


## Validation of the required argiments
if(is.na(opt$observed)){
  stop("Input is not specified.\n")
}
if(is.na(opt$randomized)){
  stop("Input is not specified.\n")
}
if(is.na(opt$output)){
  stop("Output directory is not specified.\n")
}

## Function to convert text "NA"s to NA
to_na <- function(x){ 
  if(x %in% "NA"){ x <- NA }
  return(x)
}

## Assign variables
OBSERVED <- opt$observed
RANDOMIZED <- opt$randomized
CPUTHREADS <- as.numeric(opt$threads)
OUTPUT <- opt$output

## Log assigned variables
cat(paste("Input, observed values: ", OBSERVED, "\n", sep=""))
cat(paste("Input, randomized values: ", RANDOMIZED, "\n", sep=""))
cat(paste("Number of CPU threads to use: ", CPUTHREADS, "\n", sep=""))
cat(paste("Output file: ", OUTPUT, "\n", sep=""))

cat("\n")


############################################## Load packages

cat("Loading R packages...\n")

load_pckg <- function(pkg = "data.table"){
  suppressPackageStartupMessages( library(package = pkg, character.only = TRUE) )
  cat(paste(pkg, packageVersion(pkg), "\n"))
}

load_pckg("data.table")
load_pckg("h3")
load_pckg("plyr")

cat("\n")


## Set CPU thread pool
cat("Setting number of CPU threads to: ", CPUTHREADS, "\n")
setDTthreads(threads = CPUTHREADS)  # for data.table

# ## Start local cluster
# if(CPUTHREADS > 1){
#   load_pckg("doFuture")
#   registerDoFuture()
#   plan(multicore, workers = CPUTHREADS)
#   options(future.globals.maxSize = 1e10)
# 
#   parall <- TRUE
# } else {
#   parall <- FALSE
# }


############################################## Main pipeline

cat("Loading input data...\n")

## Load observed values
obs <- fread(OBSERVED)
obs[, Axis_0 := NULL ]

## Load randomization results  - "*_rand--SPATIAL_RESULTS.csv"
rndfiles <- read.delim(file = RANDOMIZED, header = FALSE, sep = "\t", col.names = "FileID")
datt <- alply(.data = rndfiles$FileID, .margins = 1, .fun = fread)

## Bind randomization chunks together
datt <- rbindlist(datt)

## Remove useless columns
datt[, Axis_0 := NULL ]


cat("Processing data...\n")

## Reshape data to long format
datl <- melt(data = datt, id.vars = c("ELEMENT"),
  variable.name = "IndexName", value.name = "Value")

## Add index types
datl[, IndexType := tstrsplit(x = IndexName, split = "_", keep = 1)]

## Estimate the number of randomization iterations
## beacause of undefined values, it could be different for different samples and indices
niter <- datl[ 
  IndexType %in% "Q" , 
  .(NIter = sum(Value, na.rm = TRUE)), 
  by = c("ELEMENT", "IndexName")]

niter[, IndexName := gsub(pattern = "^Q_", replacement = "", x = IndexName) ]


## Prepare data for Z-score estimation
ZSCOREL <- datl[ 
  IndexType %in% c("SUMX", "SUMXX"),
  .(Sum = sum(Value, na.rm = TRUE)),
  , by = c("ELEMENT", "IndexName", "IndexType")]

## Remove index name prefix
ZSCOREL[, IndexName := gsub(pattern = "^SUMX_|^SUMXX_", replacement = "", x = IndexName) ]

## Reshape to wide format
ZSCORE <- dcast(data = ZSCOREL,
  formula = ELEMENT + IndexName ~ IndexType,
  fun.aggregate = sum, fill = NA, value.var = "Sum")


## Reshape observed values into long format
obsl <- melt(data = obs, id.vars = "ELEMENT",
  variable.name = "IndexName", value.name = "Observed")

## Add observed values to the table with randomizations
if(any(!unique(ZSCORE$IndexName) %in% unique(obsl$IndexName))){
  cat("WARNING: index names mismatches with observed data.\n")
}

ZSCORE <- merge(x = ZSCORE, y = obsl, by = c("ELEMENT", "IndexName"), all.x = TRUE)


## There are some indices without SUMX and SUMXX
# ii <- unique(obsl$IndexName)[ !unique(obsl$IndexName) %in% unique(ZSCORE$IndexName) ]
# obsl[ IndexName %in% ii ]
##     e.g., PMPD1_MAX  PMPD1_MEAN PMPD1_MIN  PMPD1_RMSD PNTD1_MAX  PNTD1_MEAN PNTD1_MIN  PNTD1_RMSD


## Add number of iterations
if(any(!unique(ZSCORE$IndexName) %in% unique(niter$IndexName))){
  cat("WARNING: index names mismatches with randomization-based data.\n")
}

ZSCORE <- merge(x = ZSCORE, y = niter, by = c("ELEMENT", "IndexName"), all.x = TRUE)


cat("Estimating Z-scores...\n")

## Estimate variance of null-distribuition (from randomized values)
ZSCORE[ , VAR := ((SUMXX/NIter) - (SUMX/NIter)^2)  ]

## Define tolerance threshold (a value less than tol is considered equal to zero)
## Biodiverse uses tol = 1e-10  (https://github.com/shawnlaffan/biodiverse/commit/5a1ca6aaa11c95ab870e8553f4d7750c37af9efd)
tol = .Machine$double.eps              # 2.220446e-16
ZSCORE[ abs(VAR) < tol  , VAR := 0 ]

## SD of null-distribuition
ZSCORE[ , SD := sqrt(VAR) ]

## Estimate Z-scores
ZSCORE[ , ZScore := (Observed - (SUMX/NIter)) / SD ]

## Replace -Inf and Inf by zero
ZSCORE[ is.infinite(ZScore), ZScore := 0 ]

## Replace NaN by zero
ZSCORE[ is.nan(ZScore), ZScore := 0 ]


## How to deal with NAs??


## Add coordinates to the table
coords <- data.table(ELEMENT = unique(obs$ELEMENT))
crd <- h3::h3_to_geo(h3_index = coords$ELEMENT)
coords <- cbind(coords, crd)
rm(crd)

ZSCORE <- merge(x = ZSCORE, y = coords, by = "ELEMENT", all.x = TRUE)

## Reorder columns
setcolorder(ZSCORE, c("ELEMENT", "lat", "lng", "IndexName"))


## Export results
cat("Exporting data...\n")

fwrite(x = ZSCORE, file = OUTPUT, quote = F, sep = "\t")



## Compare with Biodiverse Z-scores
# zzl <- melt(data = zz, id.vars = "ELEMENT", variable.name = "IndexName", value.name = "BZ")
# ZSCORE <- merge(x = ZSCORE, y = zzl, by = c("ELEMENT", "IndexName"), all.x = TRUE)
# ggplot(data = ZSCORE, aes(x = BZ, y = ZScore)) + 
#   geom_point() + annotate("segment", x=-Inf, xend=Inf,y=-Inf, yend=Inf) + facet_wrap(~ IndexName, scales = "free") +
#   labs(x = "Biodiverse Z-score", y = "Manual Z-score")



cat("All done.\n")

#####################

## Check time
end_time <- Sys.time()

tmm <- as.numeric(difftime(end_time, start_time, units = "min"))
cat("\nElapsed time: ", tmm, " minutes\n")


cat("\n")
cat("Session info:\n")
sessionInfo()
cat("\n")
